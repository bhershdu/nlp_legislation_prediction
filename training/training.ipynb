{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TitlePartyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TitlePartyModel, self).__init__()\n",
    "        self.input = torch.nn.Linear(2048,2048, dtype=torch.float32)\n",
    "        self.input_activation = torch.nn.Sigmoid()\n",
    "        self.hidden1 = torch.nn.Linear(2048,1024)\n",
    "        self.hidden1_activation = torch.nn.Sigmoid()\n",
    "        self.hidden2 = torch.nn.Linear(1024,128)\n",
    "        self.hidden2_activation = torch.nn.Sigmoid()\n",
    "        # 4 political party choices\n",
    "        self.hidden3 = torch.nn.Linear(128,4)\n",
    "        self.output = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.input_activation(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden1_activation(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.hidden2_activation(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model\n",
      "TitlePartyModel(\n",
      "  (input): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (input_activation): Sigmoid()\n",
      "  (hidden1): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (hidden1_activation): Sigmoid()\n",
      "  (hidden2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (hidden2_activation): Sigmoid()\n",
      "  (hidden3): Linear(in_features=128, out_features=4, bias=True)\n",
      "  (output): Softmax(dim=None)\n",
      ")\n",
      "just the 2nd layer\n",
      "Linear(in_features=2048, out_features=1024, bias=True)\n",
      "parameters\n",
      "Parameter containing:\n",
      "tensor([[-0.0196, -0.0152, -0.0169,  ...,  0.0058, -0.0030, -0.0084],\n",
      "        [-0.0201, -0.0107, -0.0048,  ...,  0.0093, -0.0132,  0.0191],\n",
      "        [-0.0071,  0.0046,  0.0114,  ..., -0.0028,  0.0165,  0.0031],\n",
      "        ...,\n",
      "        [ 0.0016, -0.0090,  0.0186,  ...,  0.0184, -0.0208, -0.0085],\n",
      "        [ 0.0102, -0.0039, -0.0145,  ..., -0.0048, -0.0115, -0.0006],\n",
      "        [-0.0142,  0.0072, -0.0145,  ...,  0.0125,  0.0216, -0.0064]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0144, -0.0162,  0.0132,  ..., -0.0092, -0.0073,  0.0154],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0086, -0.0115, -0.0047,  ...,  0.0221, -0.0159, -0.0034],\n",
      "        [-0.0024, -0.0221,  0.0207,  ...,  0.0176, -0.0017,  0.0002],\n",
      "        [-0.0209, -0.0203,  0.0153,  ...,  0.0134,  0.0164,  0.0007],\n",
      "        ...,\n",
      "        [ 0.0199,  0.0033, -0.0074,  ..., -0.0130,  0.0147, -0.0106],\n",
      "        [ 0.0170,  0.0085,  0.0185,  ..., -0.0169, -0.0182, -0.0069],\n",
      "        [-0.0096,  0.0004, -0.0004,  ..., -0.0030, -0.0199,  0.0104]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0057,  0.0038,  0.0083,  ..., -0.0176, -0.0071,  0.0170],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0126,  0.0271, -0.0083,  ..., -0.0024,  0.0220,  0.0302],\n",
      "        [ 0.0260,  0.0034, -0.0278,  ...,  0.0055,  0.0234, -0.0282],\n",
      "        [ 0.0231, -0.0291, -0.0133,  ..., -0.0140,  0.0078, -0.0017],\n",
      "        ...,\n",
      "        [-0.0080, -0.0239, -0.0156,  ...,  0.0105, -0.0202, -0.0198],\n",
      "        [ 0.0258,  0.0226, -0.0151,  ..., -0.0011, -0.0144,  0.0143],\n",
      "        [-0.0158, -0.0273, -0.0071,  ...,  0.0222, -0.0014,  0.0285]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0121,  0.0153,  0.0010, -0.0158,  0.0100, -0.0303,  0.0084,  0.0043,\n",
      "         0.0040, -0.0206,  0.0232, -0.0062, -0.0259, -0.0240,  0.0132, -0.0119,\n",
      "         0.0169, -0.0032, -0.0172,  0.0126,  0.0308, -0.0209,  0.0269,  0.0162,\n",
      "        -0.0015, -0.0074, -0.0023,  0.0061, -0.0117,  0.0169,  0.0077, -0.0030,\n",
      "         0.0083, -0.0280, -0.0027, -0.0214,  0.0167, -0.0223,  0.0088,  0.0258,\n",
      "         0.0018, -0.0224, -0.0107, -0.0042, -0.0066, -0.0250, -0.0269, -0.0002,\n",
      "        -0.0244,  0.0229,  0.0092, -0.0113, -0.0305, -0.0227,  0.0010, -0.0123,\n",
      "        -0.0068,  0.0006, -0.0292,  0.0298, -0.0147,  0.0081,  0.0185, -0.0240,\n",
      "         0.0064, -0.0118,  0.0109,  0.0070, -0.0105, -0.0188,  0.0107,  0.0287,\n",
      "        -0.0120,  0.0203,  0.0280, -0.0038, -0.0034, -0.0223,  0.0110, -0.0261,\n",
      "        -0.0259, -0.0260, -0.0210,  0.0151,  0.0099,  0.0087, -0.0198,  0.0063,\n",
      "         0.0131, -0.0175,  0.0050,  0.0234, -0.0293, -0.0235, -0.0249, -0.0258,\n",
      "         0.0218,  0.0280, -0.0248,  0.0229, -0.0280,  0.0118, -0.0056, -0.0015,\n",
      "        -0.0248, -0.0190,  0.0100,  0.0309, -0.0062,  0.0043, -0.0208, -0.0069,\n",
      "         0.0136,  0.0189, -0.0286,  0.0084,  0.0151,  0.0180, -0.0143,  0.0103,\n",
      "         0.0262,  0.0291,  0.0201, -0.0159, -0.0206,  0.0273, -0.0290, -0.0078],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0674, -0.0393, -0.0751, -0.0792,  0.0766, -0.0294,  0.0211,  0.0352,\n",
      "          0.0194, -0.0467,  0.0147,  0.0374,  0.0735,  0.0669,  0.0518, -0.0797,\n",
      "          0.0381,  0.0704, -0.0836,  0.0260,  0.0145,  0.0668, -0.0640,  0.0529,\n",
      "         -0.0514,  0.0850,  0.0052, -0.0734, -0.0107, -0.0109,  0.0533,  0.0481,\n",
      "          0.0717, -0.0383,  0.0308, -0.0738, -0.0092, -0.0356,  0.0640,  0.0224,\n",
      "         -0.0664,  0.0653,  0.0756,  0.0376, -0.0152, -0.0629,  0.0770, -0.0865,\n",
      "         -0.0228, -0.0765, -0.0647, -0.0772, -0.0284,  0.0099, -0.0443, -0.0073,\n",
      "         -0.0076,  0.0505, -0.0142,  0.0118,  0.0556,  0.0746, -0.0436,  0.0379,\n",
      "          0.0244, -0.0106,  0.0316,  0.0462, -0.0012,  0.0097, -0.0481, -0.0305,\n",
      "          0.0305,  0.0199, -0.0656, -0.0249,  0.0254, -0.0631, -0.0720, -0.0748,\n",
      "          0.0108, -0.0080,  0.0864, -0.0272,  0.0865,  0.0514,  0.0394,  0.0795,\n",
      "         -0.0462,  0.0748, -0.0496,  0.0636,  0.0525,  0.0523,  0.0858,  0.0085,\n",
      "         -0.0556,  0.0420, -0.0800,  0.0388,  0.0446, -0.0361,  0.0507,  0.0494,\n",
      "          0.0709,  0.0695, -0.0666,  0.0252,  0.0831, -0.0571, -0.0746, -0.0612,\n",
      "         -0.0733, -0.0053,  0.0611, -0.0152, -0.0479, -0.0066,  0.0485,  0.0315,\n",
      "         -0.0723, -0.0209,  0.0094, -0.0604, -0.0156, -0.0855, -0.0257, -0.0630],\n",
      "        [-0.0170, -0.0437,  0.0417, -0.0595, -0.0300, -0.0370,  0.0441, -0.0520,\n",
      "         -0.0091,  0.0204,  0.0084,  0.0673, -0.0575, -0.0803, -0.0661, -0.0602,\n",
      "         -0.0236, -0.0512, -0.0113,  0.0766,  0.0519,  0.0198, -0.0370, -0.0725,\n",
      "          0.0397,  0.0228, -0.0858,  0.0648,  0.0736,  0.0318,  0.0543,  0.0123,\n",
      "          0.0495, -0.0759, -0.0484,  0.0158, -0.0063, -0.0239, -0.0568, -0.0119,\n",
      "         -0.0216, -0.0662, -0.0228, -0.0451, -0.0797, -0.0459,  0.0669, -0.0498,\n",
      "         -0.0403, -0.0399,  0.0050, -0.0115,  0.0335, -0.0880, -0.0859, -0.0627,\n",
      "          0.0084, -0.0511, -0.0683,  0.0337,  0.0802, -0.0803,  0.0805, -0.0144,\n",
      "          0.0777,  0.0188, -0.0682,  0.0207, -0.0561, -0.0045,  0.0776,  0.0322,\n",
      "         -0.0328, -0.0202,  0.0246, -0.0214, -0.0543, -0.0341, -0.0283,  0.0228,\n",
      "          0.0248, -0.0259,  0.0163, -0.0453,  0.0823, -0.0808, -0.0203,  0.0533,\n",
      "          0.0387,  0.0417, -0.0772,  0.0355,  0.0670, -0.0654,  0.0288, -0.0013,\n",
      "          0.0797,  0.0410, -0.0784,  0.0223, -0.0040,  0.0368, -0.0447, -0.0342,\n",
      "          0.0044, -0.0449,  0.0622,  0.0700, -0.0802,  0.0087, -0.0368,  0.0682,\n",
      "          0.0439, -0.0750, -0.0757, -0.0825,  0.0497,  0.0767, -0.0447,  0.0876,\n",
      "          0.0463,  0.0689,  0.0051, -0.0767, -0.0361,  0.0491, -0.0008,  0.0299],\n",
      "        [-0.0064,  0.0375,  0.0794,  0.0026, -0.0738, -0.0027, -0.0565, -0.0817,\n",
      "          0.0283,  0.0470, -0.0347,  0.0766, -0.0504,  0.0250, -0.0078, -0.0087,\n",
      "         -0.0247,  0.0011,  0.0052,  0.0078, -0.0772,  0.0871, -0.0550, -0.0438,\n",
      "          0.0345,  0.0806, -0.0513, -0.0314,  0.0804, -0.0757,  0.0361, -0.0319,\n",
      "          0.0506, -0.0226, -0.0723,  0.0269,  0.0196,  0.0361,  0.0540, -0.0494,\n",
      "         -0.0298, -0.0818, -0.0781, -0.0441, -0.0620, -0.0553,  0.0609,  0.0499,\n",
      "          0.0587,  0.0556,  0.0156, -0.0175,  0.0198, -0.0330, -0.0598, -0.0262,\n",
      "         -0.0702,  0.0430,  0.0754,  0.0856, -0.0375,  0.0165,  0.0237, -0.0110,\n",
      "         -0.0760,  0.0750, -0.0063, -0.0292, -0.0757,  0.0044, -0.0414, -0.0289,\n",
      "         -0.0566,  0.0515, -0.0549, -0.0788,  0.0223,  0.0244, -0.0788,  0.0319,\n",
      "          0.0623, -0.0061, -0.0471,  0.0645, -0.0606, -0.0722,  0.0194,  0.0399,\n",
      "         -0.0214,  0.0097, -0.0533,  0.0163,  0.0428,  0.0299,  0.0450, -0.0638,\n",
      "         -0.0726, -0.0881, -0.0438,  0.0831,  0.0394, -0.0176, -0.0018, -0.0615,\n",
      "         -0.0236,  0.0763, -0.0599,  0.0779,  0.0455, -0.0580, -0.0235, -0.0077,\n",
      "          0.0385, -0.0413,  0.0082,  0.0441,  0.0817,  0.0801, -0.0784, -0.0171,\n",
      "          0.0286,  0.0111, -0.0163,  0.0722,  0.0711, -0.0831, -0.0331, -0.0752],\n",
      "        [-0.0568, -0.0819,  0.0854, -0.0090, -0.0342,  0.0259,  0.0286,  0.0238,\n",
      "          0.0148,  0.0027,  0.0319,  0.0238, -0.0706,  0.0616,  0.0773, -0.0683,\n",
      "         -0.0724, -0.0516,  0.0707,  0.0572, -0.0090, -0.0813, -0.0200,  0.0063,\n",
      "          0.0769,  0.0721,  0.0369, -0.0081, -0.0677, -0.0165, -0.0810, -0.0686,\n",
      "         -0.0524,  0.0612, -0.0691, -0.0373,  0.0098, -0.0514,  0.0320,  0.0861,\n",
      "         -0.0681,  0.0619,  0.0595,  0.0198, -0.0175,  0.0284,  0.0199,  0.0262,\n",
      "          0.0747, -0.0387,  0.0555,  0.0566, -0.0781,  0.0350, -0.0570, -0.0783,\n",
      "          0.0021,  0.0382, -0.0749, -0.0043, -0.0775,  0.0700,  0.0425, -0.0757,\n",
      "          0.0597,  0.0552, -0.0166, -0.0229,  0.0410, -0.0744, -0.0023, -0.0866,\n",
      "          0.0377, -0.0280, -0.0785, -0.0725,  0.0007, -0.0619, -0.0388,  0.0651,\n",
      "          0.0622, -0.0786, -0.0811, -0.0538,  0.0204, -0.0485,  0.0838, -0.0248,\n",
      "         -0.0704,  0.0760, -0.0764, -0.0184,  0.0652,  0.0798, -0.0109, -0.0757,\n",
      "         -0.0166,  0.0854, -0.0259, -0.0869, -0.0512, -0.0034, -0.0214,  0.0405,\n",
      "          0.0337, -0.0142, -0.0570,  0.0346, -0.0352, -0.0790, -0.0017, -0.0426,\n",
      "         -0.0055,  0.0048,  0.0424, -0.0867,  0.0595,  0.0436, -0.0510,  0.0658,\n",
      "          0.0650, -0.0660, -0.0343,  0.0214,  0.0631, -0.0767,  0.0107,  0.0493]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0072, 0.0512, 0.0161, 0.0484], requires_grad=True)\n",
      "2nd layer params\n",
      "Parameter containing:\n",
      "tensor([[ 0.0086, -0.0115, -0.0047,  ...,  0.0221, -0.0159, -0.0034],\n",
      "        [-0.0024, -0.0221,  0.0207,  ...,  0.0176, -0.0017,  0.0002],\n",
      "        [-0.0209, -0.0203,  0.0153,  ...,  0.0134,  0.0164,  0.0007],\n",
      "        ...,\n",
      "        [ 0.0199,  0.0033, -0.0074,  ..., -0.0130,  0.0147, -0.0106],\n",
      "        [ 0.0170,  0.0085,  0.0185,  ..., -0.0169, -0.0182, -0.0069],\n",
      "        [-0.0096,  0.0004, -0.0004,  ..., -0.0030, -0.0199,  0.0104]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0057,  0.0038,  0.0083,  ..., -0.0176, -0.0071,  0.0170],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "title_model = TitlePartyModel()\n",
    "print(\"the model\")\n",
    "print(title_model)\n",
    "print(\"just the 2nd layer\")\n",
    "print(title_model.hidden1)\n",
    "print(\"parameters\")\n",
    "for p in title_model.parameters():\n",
    "    print(p)\n",
    "print(\"2nd layer params\")\n",
    "for p in title_model.hidden1.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import fnmatch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\n",
      "train: summary_bill_1811_1393180-shrunk.pkl\n",
      "train: summary_bill_1811_1393181-shrunk.pkl\n",
      "train: summary_bill_1811_1470063-shrunk.pkl\n",
      "train: summary_bill_1811_1506887-shrunk.pkl\n",
      "test : summary_bill_1959_1542899-shrunk.pkl\n",
      "train: summary_bill_1959_1545862-shrunk.pkl\n",
      "train: summary_bill_1959_1546074-shrunk.pkl\n",
      "train: summary_bill_1959_1546096-shrunk.pkl\n",
      "['C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1811_1393180-shrunk.pkl', 'C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1811_1393181-shrunk.pkl', 'C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1811_1470063-shrunk.pkl', 'C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1811_1506887-shrunk.pkl', 'C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1959_1545862-shrunk.pkl', 'C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1959_1546074-shrunk.pkl', 'C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1959_1546096-shrunk.pkl']\n",
      "['C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1959_1542899-shrunk.pkl']\n"
     ]
    }
   ],
   "source": [
    "train_files = []\n",
    "test_files = []\n",
    "split = 0.7\n",
    "token_path = os.path.join(os.getcwd(),\"..\",\"data\",\"tokenized\")\n",
    "print(token_path)\n",
    "for root, dirs, files in os.walk(token_path):\n",
    "    for f in files:\n",
    "        if fnmatch.fnmatch(f, \"*shrunk*\"):\n",
    "            if np.random.sample(1) <= split:\n",
    "                print(f'train: {f}')\n",
    "                train_files.append(os.path.join(root, f))\n",
    "            else:\n",
    "                print(f'test : {f}')\n",
    "                test_files.append(os.path.join(root, f))\n",
    "print(train_files)\n",
    "print(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SummaryDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path_arr):\n",
    "        self.data_frames = []\n",
    "        for f in file_path_arr:\n",
    "            print(f\"loading {f}\")\n",
    "            self.data_frames.append(pd.read_pickle(f, compression=\"gzip\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "#        return len(self.data_frames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        next_df = self.data_frames[0]\n",
    "        party = next_df[\"party\"][0] # they are all the same, so just pick the first one\n",
    "        encoding = torch.tensor(np.array(next_df[\"input_shrunk\"]),dtype=torch.float)\n",
    "        # 4 politcal party choices\n",
    "        party_arr = np.zeros(4,dtype=int)\n",
    "        # the party index was stored as value with a starting index of 1 -- rethink this\n",
    "        party_arr[party-1] = 1 # set the value to 1 for the party index\n",
    "        return encoding, torch.tensor(party_arr,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1811_1393180-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1811_1393181-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1811_1470063-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1811_1506887-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1959_1545862-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1959_1546074-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1959_1546096-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1959_1542899-shrunk.pkl\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_data_set = SummaryDataSet(train_files)\n",
    "test_data_set = SummaryDataSet(test_files)\n",
    "train_loader = DataLoader(train_data_set,batch_size=1,shuffle=True)\n",
    "test_loader = DataLoader(test_data_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_idx, model, summary_writer):\n",
    "    running_loss = 0\n",
    "    last_loss = 0.\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, label = data\n",
    "        input_tensor = inputs.view(1,-1)\n",
    "        outputs = model(input_tensor)\n",
    "        loss = loss_fn(outputs, label)\n",
    "        last_loss = loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        summary_idx = i * len(train_loader) + i + 1\n",
    "        summary_writer.add_scalar(\"loss/train\", last_loss, summary_idx)\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "title_model = TitlePartyModel()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.RMSprop(title_model.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 0.2062525749206543\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.9511, 0.0228, 0.0131, 0.0130]])\n",
      "LOSS train 0.2062525749206543 valid 0.0008114652591757476\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 0.0008114652591757476\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.9846, 0.0071, 0.0041, 0.0042]])\n",
      "LOSS train 0.0008114652591757476 valid 8.02781869424507e-05\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 8.02781869424507e-05\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.9946, 0.0024, 0.0015, 0.0015]])\n",
      "LOSS train 8.02781869424507e-05 valid 9.81954963208409e-06\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 9.81954963208409e-06\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[9.9792e-01, 9.2857e-04, 5.6224e-04, 5.9019e-04]])\n",
      "LOSS train 9.81954963208409e-06 valid 1.4642877204096294e-06\n",
      "turn on training\n",
      "running one epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_30240\\2359741441.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn off training\n",
      "epoch loss 1.4642877204096294e-06\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[9.9912e-01, 3.8856e-04, 2.3907e-04, 2.5540e-04]])\n",
      "LOSS train 1.4642877204096294e-06 valid 2.632287703363545e-07\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 2.632287703363545e-07\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[9.9959e-01, 1.7728e-04, 1.1066e-04, 1.2011e-04]])\n",
      "LOSS train 2.632287703363545e-07 valid 5.616389131546384e-08\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 5.616389131546384e-08\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[9.9980e-01, 8.7466e-05, 5.5312e-05, 6.0894e-05]])\n",
      "LOSS train 5.616389131546384e-08 valid 1.3974740475930503e-08\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.3974740475930503e-08\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[9.9989e-01, 4.6309e-05, 2.9630e-05, 3.3041e-05]])\n",
      "LOSS train 1.3974740475930503e-08 valid 4.002947306958049e-09\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.002947306958049e-09\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[9.9994e-01, 2.6127e-05, 1.6894e-05, 1.9057e-05]])\n",
      "LOSS train 4.002947306958049e-09 valid 1.2971479446122203e-09\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.2971479446122203e-09\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[9.9996e-01, 1.5609e-05, 1.0189e-05, 1.1613e-05]])\n",
      "LOSS train 1.2971479446122203e-09 valid 4.686316334989726e-10\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.686316334989726e-10\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[9.9998e-01, 9.8177e-06, 6.4634e-06, 7.4363e-06]])\n",
      "LOSS train 4.686316334989726e-10 valid 1.8764582943031627e-10\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.8764582943031627e-10\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[9.9998e-01, 6.4683e-06, 4.2911e-06, 4.9788e-06]])\n",
      "LOSS train 1.8764582943031627e-10 valid 8.316244914929882e-11\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 8.316244914929882e-11\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[9.9999e-01, 4.4431e-06, 2.9680e-06, 3.4698e-06]])\n",
      "LOSS train 8.316244914929882e-11 valid 3.9567470827561735e-11\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 3.9567470827561735e-11\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[9.9999e-01, 3.1688e-06, 2.1300e-06, 2.5071e-06]])\n",
      "LOSS train 3.9567470827561735e-11 valid 2.0691531821270814e-11\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 2.0691531821270814e-11\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[9.9999e-01, 2.3377e-06, 1.5801e-06, 1.8713e-06]])\n",
      "LOSS train 2.0691531821270814e-11 valid 1.1395905052946631e-11\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.1395905052946631e-11\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.7778e-06, 1.2077e-06, 1.4382e-06]])\n",
      "LOSS train 1.1395905052946631e-11 valid 6.535596282913891e-12\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 6.535596282913891e-12\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.3895e-06, 9.4827e-07, 1.1349e-06]])\n",
      "LOSS train 6.535596282913891e-12 valid 4.226927835526695e-12\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.226927835526695e-12\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.1132e-06, 7.6277e-07, 9.1695e-07]])\n",
      "LOSS train 4.226927835526695e-12 valid 2.5448228593849542e-12\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 2.5448228593849542e-12\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 9.1176e-07, 6.2706e-07, 7.5685e-07]])\n",
      "LOSS train 2.5448228593849542e-12 valid 1.7318595559381866e-12\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.7318595559381866e-12\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 7.6185e-07, 5.2569e-07, 6.3680e-07]])\n",
      "LOSS train 1.7318595559381866e-12 valid 1.1149291125750471e-12\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.1149291125750471e-12\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 6.4812e-07, 4.4855e-07, 5.4513e-07]])\n",
      "LOSS train 1.1149291125750471e-12 valid 9.259379287612779e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 9.259379287612779e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 5.6036e-07, 3.8885e-07, 4.7396e-07]])\n",
      "LOSS train 9.259379287612779e-13 valid 6.840533998617171e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 6.840533998617171e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 4.9158e-07, 3.4195e-07, 4.1789e-07]])\n",
      "LOSS train 6.840533998617171e-13 valid 5.631827469654294e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 5.631827469654294e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 4.3693e-07, 3.0459e-07, 3.7313e-07]])\n",
      "LOSS train 5.631827469654294e-13 valid 4.609983185119293e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.609983185119293e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 3.9296e-07, 2.7447e-07, 3.3695e-07]])\n",
      "LOSS train 4.609983185119293e-13 valid 3.131958397056128e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 3.131958397056128e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 3.5718e-07, 2.4992e-07, 3.0740e-07]])\n",
      "LOSS train 3.131958397056128e-13 valid 2.9850739393343095e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 2.9850739393343095e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 3.2778e-07, 2.2971e-07, 2.8303e-07]])\n",
      "LOSS train 2.9850739393343095e-13 valid 2.341600492065249e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 2.341600492065249e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 3.0339e-07, 2.1292e-07, 2.6275e-07]])\n",
      "LOSS train 2.341600492065249e-13 valid 2.2568665686284461e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 2.2568665686284461e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 2.8299e-07, 1.9886e-07, 2.4575e-07]])\n",
      "LOSS train 2.2568665686284461e-13 valid 1.7290257225098526e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.7290257225098526e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 2.6581e-07, 1.8700e-07, 2.3138e-07]])\n",
      "LOSS train 1.7290257225098526e-13 valid 1.6768842716306798e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.6768842716306798e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 2.5124e-07, 1.7693e-07, 2.1918e-07]])\n",
      "LOSS train 1.6768842716306798e-13 valid 1.244344525423019e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.244344525423019e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 2.3881e-07, 1.6834e-07, 2.0874e-07]])\n",
      "LOSS train 1.244344525423019e-13 valid 1.2105363911794897e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.2105363911794897e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 2.2815e-07, 1.6096e-07, 1.9978e-07]])\n",
      "LOSS train 1.2105363911794897e-13 valid 1.1828626728278835e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.1828626728278835e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 2.1897e-07, 1.5460e-07, 1.9204e-07]])\n",
      "LOSS train 1.1828626728278835e-13 valid 1.1599935964036467e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.1599935964036467e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 2.1102e-07, 1.4909e-07, 1.8533e-07]])\n",
      "LOSS train 1.1599935964036467e-13 valid 1.1409338643124378e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.1409338643124378e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 2.0411e-07, 1.4429e-07, 1.7949e-07]])\n",
      "LOSS train 1.1409338643124378e-13 valid 1.1249257547609609e-13\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 1.1249257547609609e-13\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.9809e-07, 1.4011e-07, 1.7440e-07]])\n",
      "LOSS train 1.1249257547609609e-13 valid 7.916431589037251e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 7.916431589037251e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.9282e-07, 1.3645e-07, 1.6993e-07]])\n",
      "LOSS train 7.916431589037251e-14 valid 7.801218845178079e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 7.801218845178079e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.8819e-07, 1.3324e-07, 1.6602e-07]])\n",
      "LOSS train 7.801218845178079e-14 valid 7.702621499612247e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 7.702621499612247e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.8413e-07, 1.3041e-07, 1.6257e-07]])\n",
      "LOSS train 7.702621499612247e-14 valid 7.617819271438578e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 7.617819271438578e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.8055e-07, 1.2792e-07, 1.5952e-07]])\n",
      "LOSS train 7.617819271438578e-14 valid 7.544548888622007e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 7.544548888622007e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.7738e-07, 1.2572e-07, 1.5683e-07]])\n",
      "LOSS train 7.544548888622007e-14 valid 4.994084911781084e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.994084911781084e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.7458e-07, 1.2377e-07, 1.5445e-07]])\n",
      "LOSS train 4.994084911781084e-14 valid 4.9387343579966256e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.9387343579966256e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.7209e-07, 1.2204e-07, 1.5234e-07]])\n",
      "LOSS train 4.9387343579966256e-14 valid 4.8903741977192675e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.8903741977192675e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.6989e-07, 1.2051e-07, 1.5046e-07]])\n",
      "LOSS train 4.8903741977192675e-14 valid 4.8480120471480065e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.8480120471480065e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.6793e-07, 1.1914e-07, 1.4879e-07]])\n",
      "LOSS train 4.8480120471480065e-14 valid 4.810782238610749e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.810782238610749e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.6618e-07, 1.1793e-07, 1.4730e-07]])\n",
      "LOSS train 4.810782238610749e-14 valid 4.777999691859755e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.777999691859755e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.6463e-07, 1.1684e-07, 1.4598e-07]])\n",
      "LOSS train 4.777999691859755e-14 valid 4.74906131943658e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.74906131943658e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.6324e-07, 1.1588e-07, 1.4480e-07]])\n",
      "LOSS train 4.74906131943658e-14 valid 4.723474148165922e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.723474148165922e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.6200e-07, 1.1501e-07, 1.4374e-07]])\n",
      "LOSS train 4.723474148165922e-14 valid 4.700805513618324e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.700805513618324e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.6090e-07, 1.1424e-07, 1.4280e-07]])\n",
      "LOSS train 4.700805513618324e-14 valid 4.6806945797582544e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.6806945797582544e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5991e-07, 1.1355e-07, 1.4195e-07]])\n",
      "LOSS train 4.6806945797582544e-14 valid 4.662822184571189e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.662822184571189e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5902e-07, 1.1294e-07, 1.4119e-07]])\n",
      "LOSS train 4.662822184571189e-14 valid 4.646917616327184e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.646917616327184e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5823e-07, 1.1238e-07, 1.4052e-07]])\n",
      "LOSS train 4.646917616327184e-14 valid 4.63275590307545e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.63275590307545e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5752e-07, 1.1189e-07, 1.3991e-07]])\n",
      "LOSS train 4.63275590307545e-14 valid 4.620129013524141e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.620129013524141e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5688e-07, 1.1145e-07, 1.3937e-07]])\n",
      "LOSS train 4.620129013524141e-14 valid 4.6088570378752594e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.6088570378752594e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5631e-07, 1.1105e-07, 1.3888e-07]])\n",
      "LOSS train 4.6088570378752594e-14 valid 4.598791575956447e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.598791575956447e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5580e-07, 1.1069e-07, 1.3844e-07]])\n",
      "LOSS train 4.598791575956447e-14 valid 4.589789987419386e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.589789987419386e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5534e-07, 1.1037e-07, 1.3805e-07]])\n",
      "LOSS train 4.589789987419386e-14 valid 4.5817421579809336e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5817421579809336e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5493e-07, 1.1008e-07, 1.3770e-07]])\n",
      "LOSS train 4.5817421579809336e-14 valid 4.574540345050199e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.574540345050199e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5456e-07, 1.0983e-07, 1.3738e-07]])\n",
      "LOSS train 4.574540345050199e-14 valid 4.5680862928053e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5680862928053e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5423e-07, 1.0959e-07, 1.3710e-07]])\n",
      "LOSS train 4.5680862928053e-14 valid 4.5623061399732365e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5623061399732365e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5393e-07, 1.0939e-07, 1.3685e-07]])\n",
      "LOSS train 4.5623061399732365e-14 valid 4.5571239924019347e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5571239924019347e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5366e-07, 1.0920e-07, 1.3662e-07]])\n",
      "LOSS train 4.5571239924019347e-14 valid 4.5524771696532976e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5524771696532976e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5342e-07, 1.0903e-07, 1.3641e-07]])\n",
      "LOSS train 4.5524771696532976e-14 valid 4.548304007728765e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.548304007728765e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5321e-07, 1.0888e-07, 1.3623e-07]])\n",
      "LOSS train 4.548304007728765e-14 valid 4.544567575991837e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.544567575991837e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5301e-07, 1.0874e-07, 1.3606e-07]])\n",
      "LOSS train 4.544567575991837e-14 valid 4.5412075656966686e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5412075656966686e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5284e-07, 1.0862e-07, 1.3591e-07]])\n",
      "LOSS train 4.5412075656966686e-14 valid 4.538192467217622e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.538192467217622e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5268e-07, 1.0851e-07, 1.3578e-07]])\n",
      "LOSS train 4.538192467217622e-14 valid 4.5354819617864084e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5354819617864084e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5254e-07, 1.0841e-07, 1.3566e-07]])\n",
      "LOSS train 4.5354819617864084e-14 valid 4.533053010106862e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.533053010106862e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5241e-07, 1.0833e-07, 1.3555e-07]])\n",
      "LOSS train 4.533053010106862e-14 valid 4.530867326289767e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.530867326289767e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5230e-07, 1.0825e-07, 1.3545e-07]])\n",
      "LOSS train 4.530867326289767e-14 valid 4.528901532225779e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.528901532225779e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5220e-07, 1.0817e-07, 1.3536e-07]])\n",
      "LOSS train 4.528901532225779e-14 valid 4.527141058948206e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.527141058948206e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5210e-07, 1.0811e-07, 1.3528e-07]])\n",
      "LOSS train 4.527141058948206e-14 valid 4.525552025139157e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.525552025139157e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5202e-07, 1.0805e-07, 1.3521e-07]])\n",
      "LOSS train 4.525552025139157e-14 valid 4.5241262992823383e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5241262992823383e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5194e-07, 1.0800e-07, 1.3515e-07]])\n",
      "LOSS train 4.5241262992823383e-14 valid 4.522841858521122e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.522841858521122e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5188e-07, 1.0795e-07, 1.3509e-07]])\n",
      "LOSS train 4.522841858521122e-14 valid 4.521690571339214e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.521690571339214e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5182e-07, 1.0791e-07, 1.3504e-07]])\n",
      "LOSS train 4.521690571339214e-14 valid 4.520655835890848e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.520655835890848e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5176e-07, 1.0787e-07, 1.3499e-07]])\n",
      "LOSS train 4.520655835890848e-14 valid 4.5197237608356894e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5197237608356894e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5171e-07, 1.0784e-07, 1.3495e-07]])\n",
      "LOSS train 4.5197237608356894e-14 valid 4.518884181778371e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.518884181778371e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5167e-07, 1.0781e-07, 1.3491e-07]])\n",
      "LOSS train 4.518884181778371e-14 valid 4.5181310000816724e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5181310000816724e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5163e-07, 1.0778e-07, 1.3488e-07]])\n",
      "LOSS train 4.5181310000816724e-14 valid 4.5174516796579745e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5174516796579745e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5159e-07, 1.0776e-07, 1.3485e-07]])\n",
      "LOSS train 4.5174516796579745e-14 valid 4.516840460683236e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.516840460683236e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5156e-07, 1.0773e-07, 1.3482e-07]])\n",
      "LOSS train 4.516840460683236e-14 valid 4.516291922146594e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.516291922146594e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5153e-07, 1.0771e-07, 1.3480e-07]])\n",
      "LOSS train 4.516291922146594e-14 valid 4.515797932531755e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.515797932531755e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5151e-07, 1.0769e-07, 1.3477e-07]])\n",
      "LOSS train 4.515797932531755e-14 valid 4.515353748454215e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.515353748454215e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5148e-07, 1.0768e-07, 1.3475e-07]])\n",
      "LOSS train 4.515353748454215e-14 valid 4.514953948903111e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.514953948903111e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5146e-07, 1.0766e-07, 1.3473e-07]])\n",
      "LOSS train 4.514953948903111e-14 valid 4.514592435241223e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.514592435241223e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5144e-07, 1.0765e-07, 1.3472e-07]])\n",
      "LOSS train 4.514592435241223e-14 valid 4.514268191029014e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.514268191029014e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5143e-07, 1.0764e-07, 1.3470e-07]])\n",
      "LOSS train 4.514268191029014e-14 valid 4.513978166947874e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.513978166947874e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5141e-07, 1.0763e-07, 1.3469e-07]])\n",
      "LOSS train 4.513978166947874e-14 valid 4.513716603173762e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.513716603173762e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5140e-07, 1.0762e-07, 1.3468e-07]])\n",
      "LOSS train 4.513716603173762e-14 valid 4.513479095135352e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.513479095135352e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5139e-07, 1.0761e-07, 1.3467e-07]])\n",
      "LOSS train 4.513479095135352e-14 valid 4.5132697085907905e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5132697085907905e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5137e-07, 1.0760e-07, 1.3466e-07]])\n",
      "LOSS train 4.5132697085907905e-14 valid 4.5130762462656376e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5130762462656376e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5136e-07, 1.0759e-07, 1.3465e-07]])\n",
      "LOSS train 4.5130762462656376e-14 valid 4.512902435104861e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.512902435104861e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5136e-07, 1.0759e-07, 1.3464e-07]])\n",
      "LOSS train 4.512902435104861e-14 valid 4.5127486139216397e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5127486139216397e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5135e-07, 1.0758e-07, 1.3464e-07]])\n",
      "LOSS train 4.5127486139216397e-14 valid 4.5126107169578267e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5126107169578267e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5134e-07, 1.0758e-07, 1.3463e-07]])\n",
      "LOSS train 4.5126107169578267e-14 valid 4.5124867113343486e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.5124867113343486e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5133e-07, 1.0757e-07, 1.3462e-07]])\n",
      "LOSS train 4.5124867113343486e-14 valid 4.512374564172132e-14\n",
      "turn on training\n",
      "running one epoch\n",
      "turn off training\n",
      "epoch loss 4.512374564172132e-14\n",
      "applying model.eval()\n",
      "validation 0\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[1.0000e+00, 1.5133e-07, 1.0757e-07, 1.3462e-07]])\n",
      "LOSS train 4.512374564172132e-14 valid 4.512274953097535e-14\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "start_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(start_time))\n",
    "EPOCHS = 100\n",
    "epoch_num = 0\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"turn on training\")\n",
    "    title_model.train(True)\n",
    "    print(\"running one epoch\")\n",
    "    last_epoch_loss = train_one_epoch(epoch_num,title_model, writer)\n",
    "    train_losses.append(last_epoch_loss)\n",
    "    print(\"turn off training\")\n",
    "    print(f'epoch loss {last_epoch_loss}')\n",
    "\n",
    "    # title_model.train(False)\n",
    "\n",
    "    running_validation_loss = 0.0\n",
    "    print(\"applying model.eval()\")\n",
    "    title_model.eval()\n",
    "    with (torch.no_grad()):\n",
    "        for i, vdata in enumerate(train_loader):\n",
    "            print(f\"validation {i}\")\n",
    "            vinputs, vlabel = vdata\n",
    "            print(f\"label : {vlabel}\")\n",
    "            voutputs = title_model(vinputs)\n",
    "            print(f\"vOutput: {voutputs}\")\n",
    "            vloss = loss_fn(voutputs, vlabel)\n",
    "            running_validation_loss += vloss\n",
    "\n",
    "    avg_vloss = running_validation_loss / len(test_loader)\n",
    "    val_losses.append(avg_vloss)\n",
    "    print('LOSS train {} valid {}'.format(last_epoch_loss, avg_vloss))\n",
    "#    writer.add_scalars(\"Training vs Valiation loss\",{\"training\": last_epoch_loss, \"validation\": avg_vloss}, epoch_num+1)\n",
    "#    writer.flush()\n",
    "    epoch_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "4.512374564172132e-14"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_values = list(map(lambda x : x.item(), val_losses))\n",
    "train_losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(100), val_losses)\n",
    "plt.yscale('log')\n",
    "plt.title(\"validation loss vs epoch\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(100), train_losses)\n",
    "plt.yscale('log')\n",
    "plt.title(\"training loss vs epoch\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}