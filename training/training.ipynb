{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TitlePartyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TitlePartyModel, self).__init__()\n",
    "        self.input = torch.nn.Linear(2048,2048, dtype=torch.float32)\n",
    "        self.input_activation = torch.nn.Sigmoid()\n",
    "        self.hidden1 = torch.nn.Linear(2048,2*2048)\n",
    "        self.hidden1_activation = torch.nn.Sigmoid()\n",
    "        self.hidden2 = torch.nn.Linear(2*2048,128)\n",
    "        self.hidden2_activation = torch.nn.Sigmoid()\n",
    "        # 4 political party choices\n",
    "        self.hidden3 = torch.nn.Linear(128,4)\n",
    "        self.output = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.input_activation(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden1_activation(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.hidden2_activation(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model\n",
      "TitlePartyModel(\n",
      "  (input): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (input_activation): Sigmoid()\n",
      "  (hidden1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "  (hidden1_activation): Sigmoid()\n",
      "  (hidden2): Linear(in_features=4096, out_features=128, bias=True)\n",
      "  (hidden2_activation): Sigmoid()\n",
      "  (hidden3): Linear(in_features=128, out_features=4, bias=True)\n",
      "  (output): Softmax(dim=None)\n",
      ")\n",
      "just the 2nd layer\n",
      "Linear(in_features=2048, out_features=4096, bias=True)\n",
      "parameters\n",
      "Parameter containing:\n",
      "tensor([[ 0.0096, -0.0070,  0.0135,  ..., -0.0206, -0.0211, -0.0002],\n",
      "        [ 0.0089, -0.0115,  0.0043,  ..., -0.0040, -0.0093, -0.0029],\n",
      "        [-0.0154, -0.0010,  0.0078,  ..., -0.0210, -0.0059, -0.0199],\n",
      "        ...,\n",
      "        [ 0.0219, -0.0059, -0.0082,  ..., -0.0195,  0.0005,  0.0014],\n",
      "        [-0.0078,  0.0055, -0.0177,  ...,  0.0065,  0.0131,  0.0144],\n",
      "        [ 0.0141,  0.0005,  0.0211,  ...,  0.0064, -0.0143, -0.0090]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0052,  0.0101, -0.0107,  ...,  0.0157, -0.0217, -0.0036],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0054, -0.0104,  0.0067,  ...,  0.0199,  0.0218,  0.0062],\n",
      "        [ 0.0031, -0.0036, -0.0032,  ...,  0.0139, -0.0200,  0.0133],\n",
      "        [-0.0035, -0.0012, -0.0102,  ...,  0.0012, -0.0188,  0.0123],\n",
      "        ...,\n",
      "        [-0.0004,  0.0013, -0.0211,  ...,  0.0113, -0.0057,  0.0186],\n",
      "        [ 0.0153,  0.0037, -0.0122,  ..., -0.0001, -0.0154,  0.0145],\n",
      "        [ 0.0068,  0.0101, -0.0125,  ...,  0.0161, -0.0153, -0.0057]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0117, -0.0078, -0.0141,  ..., -0.0133, -0.0108, -0.0081],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.3879e-02,  6.2301e-03, -1.5033e-02,  ..., -1.2829e-03,\n",
      "         -1.5118e-02,  3.3119e-03],\n",
      "        [-8.9294e-03,  2.5539e-03, -7.9818e-03,  ..., -1.3293e-02,\n",
      "          4.9715e-03,  7.6635e-03],\n",
      "        [ 1.0746e-02,  7.0046e-03, -1.1204e-02,  ...,  7.9112e-03,\n",
      "         -5.4489e-03, -1.0256e-02],\n",
      "        ...,\n",
      "        [-6.0326e-04,  1.2228e-02,  7.2031e-03,  ...,  1.1880e-02,\n",
      "          3.2111e-03, -7.5275e-03],\n",
      "        [ 3.2579e-03, -4.2283e-04, -6.9073e-03,  ...,  7.3790e-03,\n",
      "          4.4200e-03, -3.9930e-05],\n",
      "        [-1.3915e-02,  7.3150e-04,  4.7379e-03,  ...,  1.7182e-03,\n",
      "         -1.1501e-02,  3.0126e-03]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-7.5794e-03,  1.2470e-02, -1.4600e-02, -9.0331e-03,  4.1008e-03,\n",
      "         8.1814e-03, -1.6766e-03, -2.9875e-03,  2.1917e-03,  7.5570e-03,\n",
      "         1.1166e-02, -7.5011e-03, -5.3891e-03,  3.5053e-03, -2.1819e-04,\n",
      "        -1.0371e-02, -3.4319e-03,  1.0347e-02, -7.1167e-03, -1.3098e-03,\n",
      "        -6.2154e-04,  4.8247e-03, -1.2579e-02, -1.3420e-02, -2.2834e-03,\n",
      "        -1.3152e-02, -9.6567e-03, -5.6020e-04,  9.6706e-03, -1.3339e-02,\n",
      "         1.2096e-02,  1.1581e-02, -1.0493e-02, -5.3524e-03, -5.2647e-03,\n",
      "         2.6375e-03,  1.4069e-02,  4.2576e-03,  1.5204e-02,  3.8724e-03,\n",
      "         1.1221e-03,  7.9395e-03, -4.9686e-03,  1.3947e-02,  9.9936e-03,\n",
      "         1.3422e-02, -1.5594e-02,  4.9382e-03,  1.1463e-02,  6.0882e-03,\n",
      "         2.8280e-03,  3.2269e-04,  4.4001e-03, -1.3176e-02,  4.3411e-03,\n",
      "        -1.4417e-02,  8.0363e-03, -8.1539e-04, -3.5810e-03,  7.7654e-03,\n",
      "        -1.1996e-02, -5.5534e-03,  3.3908e-03, -8.5147e-03,  7.6169e-03,\n",
      "         7.7358e-03, -1.1437e-02,  1.1678e-02, -5.2192e-03,  1.0149e-02,\n",
      "        -6.8325e-03, -7.9074e-03, -6.6509e-04, -3.0352e-04, -1.0930e-02,\n",
      "         3.8873e-03,  1.1646e-02,  1.0622e-02,  1.3095e-02, -5.4186e-03,\n",
      "        -1.3310e-02,  4.2239e-03,  7.1279e-04, -1.0007e-02, -1.2040e-02,\n",
      "        -7.3280e-03,  8.5745e-03,  3.4609e-03,  9.1598e-03, -3.2142e-03,\n",
      "        -8.5277e-03,  1.1724e-02, -1.4579e-02,  7.5878e-03, -1.2003e-02,\n",
      "         8.0455e-03,  5.8560e-03,  5.3290e-03,  2.9685e-03, -5.4946e-03,\n",
      "        -7.6690e-03, -1.2014e-02, -1.7321e-03, -9.0505e-03,  1.9680e-03,\n",
      "        -1.4220e-03,  1.1324e-02,  1.5131e-02,  2.3471e-03, -1.1538e-02,\n",
      "        -1.2717e-02, -5.4580e-03, -1.2998e-02,  6.6014e-03,  9.7311e-03,\n",
      "        -1.2172e-02, -5.2675e-03, -1.3382e-02,  4.2818e-03,  1.5552e-02,\n",
      "         7.1137e-03,  5.1939e-04,  1.4847e-02,  2.9827e-05,  7.1753e-03,\n",
      "        -1.4513e-02,  2.4075e-03, -8.1564e-03], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0776, -0.0643,  0.0615,  0.0046,  0.0383, -0.0750,  0.0203, -0.0471,\n",
      "         -0.0082, -0.0157, -0.0767,  0.0684, -0.0272,  0.0587,  0.0494, -0.0799,\n",
      "         -0.0720, -0.0330, -0.0307, -0.0706,  0.0748, -0.0620,  0.0224,  0.0498,\n",
      "          0.0813, -0.0331,  0.0197,  0.0027, -0.0333, -0.0492, -0.0297, -0.0385,\n",
      "          0.0398, -0.0636,  0.0232,  0.0612,  0.0687,  0.0852, -0.0847,  0.0880,\n",
      "          0.0448,  0.0802,  0.0581, -0.0864,  0.0631,  0.0810, -0.0022, -0.0871,\n",
      "          0.0602, -0.0314, -0.0544, -0.0436, -0.0005,  0.0387,  0.0327, -0.0164,\n",
      "          0.0406,  0.0034, -0.0726,  0.0133,  0.0545, -0.0461, -0.0451, -0.0695,\n",
      "         -0.0468,  0.0484, -0.0418,  0.0268,  0.0649, -0.0067,  0.0311, -0.0782,\n",
      "          0.0863,  0.0443,  0.0781, -0.0832,  0.0339,  0.0657,  0.0393,  0.0731,\n",
      "          0.0032,  0.0783, -0.0378, -0.0658,  0.0448, -0.0429,  0.0345,  0.0387,\n",
      "          0.0743,  0.0466,  0.0598, -0.0835,  0.0818, -0.0648, -0.0599, -0.0386,\n",
      "          0.0731, -0.0738,  0.0121,  0.0478,  0.0339, -0.0420,  0.0630,  0.0842,\n",
      "          0.0390,  0.0570, -0.0592,  0.0693, -0.0096, -0.0846, -0.0429, -0.0295,\n",
      "          0.0442, -0.0490,  0.0137, -0.0626,  0.0805,  0.0298, -0.0868,  0.0649,\n",
      "         -0.0811,  0.0829,  0.0301,  0.0798,  0.0717, -0.0687,  0.0008, -0.0812],\n",
      "        [ 0.0137, -0.0753, -0.0749, -0.0056,  0.0788, -0.0652, -0.0313, -0.0298,\n",
      "         -0.0699,  0.0296, -0.0732, -0.0134, -0.0032, -0.0245, -0.0006, -0.0301,\n",
      "          0.0302, -0.0264,  0.0555, -0.0347, -0.0731, -0.0742, -0.0649,  0.0174,\n",
      "         -0.0603, -0.0821, -0.0196,  0.0838, -0.0465,  0.0433, -0.0223, -0.0536,\n",
      "          0.0804,  0.0507,  0.0708, -0.0669, -0.0563,  0.0666, -0.0595,  0.0617,\n",
      "         -0.0188,  0.0577,  0.0835,  0.0106, -0.0383,  0.0793, -0.0056, -0.0275,\n",
      "         -0.0100, -0.0286,  0.0147, -0.0778,  0.0078, -0.0145, -0.0876,  0.0271,\n",
      "         -0.0185,  0.0212,  0.0361,  0.0585,  0.0358, -0.0086, -0.0747, -0.0286,\n",
      "         -0.0217, -0.0544, -0.0206,  0.0443, -0.0007,  0.0334, -0.0811,  0.0062,\n",
      "         -0.0090,  0.0142,  0.0409,  0.0276,  0.0691, -0.0313, -0.0299,  0.0290,\n",
      "         -0.0216, -0.0762, -0.0140, -0.0534, -0.0371,  0.0625,  0.0599, -0.0394,\n",
      "          0.0678,  0.0074, -0.0460,  0.0785, -0.0291, -0.0788, -0.0333, -0.0288,\n",
      "         -0.0758, -0.0686, -0.0090, -0.0243,  0.0113,  0.0270, -0.0702,  0.0799,\n",
      "         -0.0027,  0.0716, -0.0041, -0.0792, -0.0719, -0.0216,  0.0598,  0.0268,\n",
      "          0.0120,  0.0289,  0.0871, -0.0540,  0.0201, -0.0200, -0.0709, -0.0546,\n",
      "          0.0790, -0.0057, -0.0805,  0.0587,  0.0088,  0.0551, -0.0230,  0.0587],\n",
      "        [ 0.0846,  0.0633, -0.0556, -0.0392,  0.0232,  0.0012, -0.0235,  0.0557,\n",
      "          0.0860,  0.0452,  0.0872,  0.0505,  0.0143,  0.0274, -0.0520, -0.0240,\n",
      "         -0.0512,  0.0118, -0.0567, -0.0686, -0.0871,  0.0623,  0.0030,  0.0112,\n",
      "          0.0658,  0.0569, -0.0422, -0.0528, -0.0206, -0.0423,  0.0808, -0.0582,\n",
      "          0.0512, -0.0018, -0.0281,  0.0742,  0.0004,  0.0296, -0.0573,  0.0108,\n",
      "         -0.0654, -0.0062, -0.0656, -0.0019,  0.0676,  0.0878, -0.0650,  0.0839,\n",
      "         -0.0252, -0.0322,  0.0353,  0.0143,  0.0351, -0.0117,  0.0053, -0.0828,\n",
      "         -0.0423, -0.0531,  0.0521, -0.0106, -0.0180, -0.0350,  0.0595, -0.0504,\n",
      "          0.0408, -0.0007, -0.0744, -0.0717,  0.0361,  0.0620, -0.0183, -0.0622,\n",
      "          0.0693, -0.0003, -0.0879, -0.0459, -0.0524, -0.0452, -0.0461, -0.0024,\n",
      "          0.0144,  0.0591,  0.0002,  0.0636,  0.0794, -0.0565,  0.0095,  0.0384,\n",
      "         -0.0273, -0.0057, -0.0604,  0.0774, -0.0457,  0.0282,  0.0243,  0.0029,\n",
      "         -0.0393,  0.0466, -0.0018,  0.0671,  0.0204,  0.0724,  0.0315,  0.0664,\n",
      "          0.0273, -0.0315,  0.0733,  0.0598,  0.0793, -0.0115,  0.0281, -0.0515,\n",
      "          0.0487, -0.0620,  0.0094,  0.0068, -0.0282, -0.0195,  0.0226, -0.0354,\n",
      "          0.0310, -0.0048,  0.0050, -0.0288, -0.0225, -0.0072,  0.0653,  0.0091],\n",
      "        [-0.0259, -0.0468,  0.0732, -0.0211,  0.0136, -0.0075, -0.0048,  0.0615,\n",
      "         -0.0572, -0.0589, -0.0619, -0.0260,  0.0017,  0.0043, -0.0581,  0.0620,\n",
      "         -0.0761,  0.0668, -0.0208,  0.0771,  0.0593, -0.0648, -0.0497,  0.0482,\n",
      "          0.0319, -0.0605, -0.0632,  0.0716,  0.0259, -0.0526, -0.0499,  0.0746,\n",
      "         -0.0583,  0.0800, -0.0698,  0.0149,  0.0350, -0.0727, -0.0820,  0.0399,\n",
      "         -0.0643, -0.0009, -0.0557,  0.0271, -0.0852,  0.0122, -0.0314,  0.0483,\n",
      "         -0.0513, -0.0389, -0.0407, -0.0664,  0.0317, -0.0259,  0.0793,  0.0666,\n",
      "         -0.0315, -0.0343, -0.0405, -0.0653,  0.0192, -0.0209, -0.0027,  0.0265,\n",
      "          0.0289,  0.0087,  0.0294, -0.0562, -0.0614, -0.0287, -0.0371, -0.0102,\n",
      "          0.0293,  0.0308, -0.0835, -0.0600, -0.0093, -0.0868, -0.0507,  0.0361,\n",
      "          0.0011,  0.0437, -0.0828, -0.0498, -0.0021,  0.0246, -0.0366, -0.0879,\n",
      "         -0.0364, -0.0705,  0.0649, -0.0751, -0.0252, -0.0435,  0.0419,  0.0425,\n",
      "          0.0068, -0.0025,  0.0730,  0.0863,  0.0489,  0.0398,  0.0152, -0.0555,\n",
      "          0.0062,  0.0427,  0.0488, -0.0573,  0.0433,  0.0580, -0.0237,  0.0167,\n",
      "          0.0636, -0.0409,  0.0465,  0.0574, -0.0522,  0.0711,  0.0053,  0.0562,\n",
      "         -0.0214, -0.0052, -0.0174, -0.0214,  0.0616,  0.0447, -0.0612,  0.0017]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0143,  0.0388, -0.0557,  0.0544], requires_grad=True)\n",
      "2nd layer params\n",
      "Parameter containing:\n",
      "tensor([[ 0.0054, -0.0104,  0.0067,  ...,  0.0199,  0.0218,  0.0062],\n",
      "        [ 0.0031, -0.0036, -0.0032,  ...,  0.0139, -0.0200,  0.0133],\n",
      "        [-0.0035, -0.0012, -0.0102,  ...,  0.0012, -0.0188,  0.0123],\n",
      "        ...,\n",
      "        [-0.0004,  0.0013, -0.0211,  ...,  0.0113, -0.0057,  0.0186],\n",
      "        [ 0.0153,  0.0037, -0.0122,  ..., -0.0001, -0.0154,  0.0145],\n",
      "        [ 0.0068,  0.0101, -0.0125,  ...,  0.0161, -0.0153, -0.0057]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0117, -0.0078, -0.0141,  ..., -0.0133, -0.0108, -0.0081],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "title_model = TitlePartyModel()\n",
    "print(\"the model\")\n",
    "print(title_model)\n",
    "print(\"just the 2nd layer\")\n",
    "print(title_model.hidden1)\n",
    "print(\"parameters\")\n",
    "for p in title_model.parameters():\n",
    "    print(p)\n",
    "print(\"2nd layer params\")\n",
    "for p in title_model.hidden1.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import fnmatch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(title_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\n",
      "train: summary_bill_1811_1393180-shrunk.pkl\n",
      "train: summary_bill_1811_1393181-shrunk.pkl\n",
      "train: summary_bill_1811_1470063-shrunk.pkl\n",
      "train: summary_bill_1811_1506887-shrunk.pkl\n",
      "test : summary_bill_1959_1542899-shrunk.pkl\n",
      "train: summary_bill_1959_1545862-shrunk.pkl\n",
      "train: summary_bill_1959_1546074-shrunk.pkl\n",
      "test : summary_bill_1959_1546096-shrunk.pkl\n",
      "['C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1811_1393180-shrunk.pkl', 'C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1811_1393181-shrunk.pkl', 'C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1811_1470063-shrunk.pkl', 'C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1811_1506887-shrunk.pkl', 'C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1959_1545862-shrunk.pkl', 'C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1959_1546074-shrunk.pkl']\n",
      "['C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1959_1542899-shrunk.pkl', 'C:\\\\Users\\\\benja\\\\git-projects\\\\bitbucket\\\\nlp_legislation_prediction\\\\training\\\\..\\\\data\\\\tokenized\\\\summary_bill_1959_1546096-shrunk.pkl']\n"
     ]
    }
   ],
   "source": [
    "train_files = []\n",
    "test_files = []\n",
    "split = 0.7\n",
    "token_path = os.path.join(os.getcwd(),\"..\",\"data\",\"tokenized\")\n",
    "print(token_path)\n",
    "for root, dirs, files in os.walk(token_path):\n",
    "    for f in files:\n",
    "        if fnmatch.fnmatch(f, \"*shrunk*\"):\n",
    "            if np.random.sample(1) <= split:\n",
    "                print(f'train: {f}')\n",
    "                train_files.append(os.path.join(root, f))\n",
    "            else:\n",
    "                print(f'test : {f}')\n",
    "                test_files.append(os.path.join(root, f))\n",
    "print(train_files)\n",
    "print(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SummaryDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path_arr):\n",
    "        self.data_frames = []\n",
    "        for f in file_path_arr:\n",
    "            print(f\"loading {f}\")\n",
    "            self.data_frames.append(pd.read_pickle(f, compression=\"gzip\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        next_df = self.data_frames[idx]\n",
    "        party = next_df[\"party\"][0] # they are all the same, so just pick the first one\n",
    "        encoding = torch.tensor(np.array(next_df[\"input_shrunk\"]),dtype=torch.float)\n",
    "        # 4 politcal party choices\n",
    "        party_arr = np.zeros(4,dtype=int)\n",
    "        # the party index was stored as value with a starting index of 1 -- rethink this\n",
    "        party_arr[party-1] = 1 # set the value to 1 for the party index\n",
    "        return encoding, torch.tensor(party_arr,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1811_1393180-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1811_1393181-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1811_1470063-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1811_1506887-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1959_1545862-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1959_1546074-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1959_1542899-shrunk.pkl\n",
      "loading C:\\Users\\benja\\git-projects\\bitbucket\\nlp_legislation_prediction\\training\\..\\data\\tokenized\\summary_bill_1959_1546096-shrunk.pkl\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_data_set = SummaryDataSet(train_files)\n",
    "test_data_set = SummaryDataSet(test_files)\n",
    "train_loader = DataLoader(train_data_set,batch_size=1,shuffle=True)\n",
    "test_loader = DataLoader(test_data_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_idx, model, summary_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, label = data\n",
    "        input_tensor = inputs.view(1,-1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_tensor)\n",
    "        loss = loss_fn(outputs, label)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        last_loss = running_loss\n",
    "        summary_idx = i * len(train_loader) + i + 1\n",
    "        summary_writer.add_scalar(\"loss/train\", last_loss, summary_idx)\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn on training\n",
      "running one epoch\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.411736\n",
      "1          5      1      0.019537\n",
      "2          5      1      0.313383\n",
      "3          5      1     -0.088169\n",
      "4          5      1     -0.271366\n",
      "...      ...    ...           ...\n",
      "2043       5      1     -0.026054\n",
      "2044       5      1     -0.318737\n",
      "2045       5      1      0.723295\n",
      "2046       5      1      0.055131\n",
      "2047       5      1     -0.453075\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3541, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          2      1      0.183673\n",
      "1          2      1      0.244852\n",
      "2          2      1     -0.095650\n",
      "3          2      1     -0.322488\n",
      "4          2      1      0.048414\n",
      "...      ...    ...           ...\n",
      "2043       2      1      0.808546\n",
      "2044       2      1     -0.472243\n",
      "2045       2      1      0.261753\n",
      "2046       2      1     -0.975441\n",
      "2047       2      1     -1.050877\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          4      1      0.169372\n",
      "1          4      1      0.090074\n",
      "2          4      1     -0.160564\n",
      "3          4      1      0.131678\n",
      "4          4      1      0.023742\n",
      "...      ...    ...           ...\n",
      "2043       4      1     -0.011668\n",
      "2044       4      1      0.040745\n",
      "2045       4      1     -1.896426\n",
      "2046       4      1     -0.620909\n",
      "2047       4      1     -1.108641\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.254739\n",
      "1          3      4     -0.195609\n",
      "2          3      4      0.126331\n",
      "3          3      4      0.262518\n",
      "4          3      4      0.010650\n",
      "...      ...    ...           ...\n",
      "2043       3      4      0.251763\n",
      "2044       3      4      0.957258\n",
      "2045       3      4     -0.232392\n",
      "2046       3      4     -0.157064\n",
      "2047       3      4     -0.443530\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.081985\n",
      "1          3      4      0.137535\n",
      "2          3      4     -0.133649\n",
      "3          3      4      0.125648\n",
      "4          3      4      0.155327\n",
      "...      ...    ...           ...\n",
      "2043       3      4     -0.287244\n",
      "2044       3      4      0.133067\n",
      "2045       3      4     -0.510854\n",
      "2046       3      4     -0.383557\n",
      "2047       3      4     -1.129584\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          1      4      0.005786\n",
      "1          1      4     -0.121680\n",
      "2          1      4      0.401604\n",
      "3          1      4     -0.332910\n",
      "4          1      4     -0.551901\n",
      "...      ...    ...           ...\n",
      "2043       1      4      0.616539\n",
      "2044       1      4      0.325676\n",
      "2045       1      4     -0.301177\n",
      "2046       1      4     -0.332650\n",
      "2047       1      4     -1.416497\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4280, grad_fn=<DivBackward1>)\n",
      "turn off training\n",
      "epoch loss 8.346179842948914\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.198884\n",
      "1          5      1     -0.333843\n",
      "2          5      1     -0.513041\n",
      "3          5      1      0.245438\n",
      "4          5      1      0.287163\n",
      "...      ...    ...           ...\n",
      "2043       5      1      0.432693\n",
      "2044       5      1     -0.518468\n",
      "2045       5      1     -0.271924\n",
      "2046       5      1     -0.210291\n",
      "2047       5      1     -0.845959\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2831, 0.2635, 0.2450, 0.2084]], grad_fn=<SoftmaxBackward0>)\n",
      "      status  party  input_shrunk\n",
      "0          1      1      0.012870\n",
      "1          1      1     -0.034266\n",
      "2          1      1      0.075810\n",
      "3          1      1      0.428671\n",
      "4          1      1      0.167113\n",
      "...      ...    ...           ...\n",
      "2043       1      1      0.735692\n",
      "2044       1      1      1.607339\n",
      "2045       1      1      0.314064\n",
      "2046       1      1     -0.266179\n",
      "2047       1      1     -0.464555\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2827, 0.2634, 0.2451, 0.2088]], grad_fn=<SoftmaxBackward0>)\n",
      "LOSS train 8.346179842948914 valid 1.3537888526916504\n",
      "turn on training\n",
      "running one epoch\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.081985\n",
      "1          3      4      0.137535\n",
      "2          3      4     -0.133649\n",
      "3          3      4      0.125648\n",
      "4          3      4      0.155327\n",
      "...      ...    ...           ...\n",
      "2043       3      4     -0.287244\n",
      "2044       3      4      0.133067\n",
      "2045       3      4     -0.510854\n",
      "2046       3      4     -0.383557\n",
      "2047       3      4     -1.129584\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.411736\n",
      "1          5      1      0.019537\n",
      "2          5      1      0.313383\n",
      "3          5      1     -0.088169\n",
      "4          5      1     -0.271366\n",
      "...      ...    ...           ...\n",
      "2043       5      1     -0.026054\n",
      "2044       5      1     -0.318737\n",
      "2045       5      1      0.723295\n",
      "2046       5      1      0.055131\n",
      "2047       5      1     -0.453075\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3541, grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      status  party  input_shrunk\n",
      "0          4      1      0.169372\n",
      "1          4      1      0.090074\n",
      "2          4      1     -0.160564\n",
      "3          4      1      0.131678\n",
      "4          4      1      0.023742\n",
      "...      ...    ...           ...\n",
      "2043       4      1     -0.011668\n",
      "2044       4      1      0.040745\n",
      "2045       4      1     -1.896426\n",
      "2046       4      1     -0.620909\n",
      "2047       4      1     -1.108641\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.254739\n",
      "1          3      4     -0.195609\n",
      "2          3      4      0.126331\n",
      "3          3      4      0.262518\n",
      "4          3      4      0.010650\n",
      "...      ...    ...           ...\n",
      "2043       3      4      0.251763\n",
      "2044       3      4      0.957258\n",
      "2045       3      4     -0.232392\n",
      "2046       3      4     -0.157064\n",
      "2047       3      4     -0.443530\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          2      1      0.183673\n",
      "1          2      1      0.244852\n",
      "2          2      1     -0.095650\n",
      "3          2      1     -0.322488\n",
      "4          2      1      0.048414\n",
      "...      ...    ...           ...\n",
      "2043       2      1      0.808546\n",
      "2044       2      1     -0.472243\n",
      "2045       2      1      0.261753\n",
      "2046       2      1     -0.975441\n",
      "2047       2      1     -1.050877\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          1      4      0.005786\n",
      "1          1      4     -0.121680\n",
      "2          1      4      0.401604\n",
      "3          1      4     -0.332910\n",
      "4          1      4     -0.551901\n",
      "...      ...    ...           ...\n",
      "2043       1      4      0.616539\n",
      "2044       1      4      0.325676\n",
      "2045       1      4     -0.301177\n",
      "2046       1      4     -0.332650\n",
      "2047       1      4     -1.416497\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4280, grad_fn=<DivBackward1>)\n",
      "turn off training\n",
      "epoch loss 8.346179842948914\n",
      "      status  party  input_shrunk\n",
      "0          1      1      0.012870\n",
      "1          1      1     -0.034266\n",
      "2          1      1      0.075810\n",
      "3          1      1      0.428671\n",
      "4          1      1      0.167113\n",
      "...      ...    ...           ...\n",
      "2043       1      1      0.735692\n",
      "2044       1      1      1.607339\n",
      "2045       1      1      0.314064\n",
      "2046       1      1     -0.266179\n",
      "2047       1      1     -0.464555\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2827, 0.2634, 0.2451, 0.2088]], grad_fn=<SoftmaxBackward0>)\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.198884\n",
      "1          5      1     -0.333843\n",
      "2          5      1     -0.513041\n",
      "3          5      1      0.245438\n",
      "4          5      1      0.287163\n",
      "...      ...    ...           ...\n",
      "2043       5      1      0.432693\n",
      "2044       5      1     -0.518468\n",
      "2045       5      1     -0.271924\n",
      "2046       5      1     -0.210291\n",
      "2047       5      1     -0.845959\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2831, 0.2635, 0.2450, 0.2084]], grad_fn=<SoftmaxBackward0>)\n",
      "LOSS train 8.346179842948914 valid 1.3537888526916504\n",
      "turn on training\n",
      "running one epoch\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.411736\n",
      "1          5      1      0.019537\n",
      "2          5      1      0.313383\n",
      "3          5      1     -0.088169\n",
      "4          5      1     -0.271366\n",
      "...      ...    ...           ...\n",
      "2043       5      1     -0.026054\n",
      "2044       5      1     -0.318737\n",
      "2045       5      1      0.723295\n",
      "2046       5      1      0.055131\n",
      "2047       5      1     -0.453075\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3541, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          2      1      0.183673\n",
      "1          2      1      0.244852\n",
      "2          2      1     -0.095650\n",
      "3          2      1     -0.322488\n",
      "4          2      1      0.048414\n",
      "...      ...    ...           ...\n",
      "2043       2      1      0.808546\n",
      "2044       2      1     -0.472243\n",
      "2045       2      1      0.261753\n",
      "2046       2      1     -0.975441\n",
      "2047       2      1     -1.050877\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.254739\n",
      "1          3      4     -0.195609\n",
      "2          3      4      0.126331\n",
      "3          3      4      0.262518\n",
      "4          3      4      0.010650\n",
      "...      ...    ...           ...\n",
      "2043       3      4      0.251763\n",
      "2044       3      4      0.957258\n",
      "2045       3      4     -0.232392\n",
      "2046       3      4     -0.157064\n",
      "2047       3      4     -0.443530\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      status  party  input_shrunk\n",
      "0          3      4      0.081985\n",
      "1          3      4      0.137535\n",
      "2          3      4     -0.133649\n",
      "3          3      4      0.125648\n",
      "4          3      4      0.155327\n",
      "...      ...    ...           ...\n",
      "2043       3      4     -0.287244\n",
      "2044       3      4      0.133067\n",
      "2045       3      4     -0.510854\n",
      "2046       3      4     -0.383557\n",
      "2047       3      4     -1.129584\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          1      4      0.005786\n",
      "1          1      4     -0.121680\n",
      "2          1      4      0.401604\n",
      "3          1      4     -0.332910\n",
      "4          1      4     -0.551901\n",
      "...      ...    ...           ...\n",
      "2043       1      4      0.616539\n",
      "2044       1      4      0.325676\n",
      "2045       1      4     -0.301177\n",
      "2046       1      4     -0.332650\n",
      "2047       1      4     -1.416497\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4280, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          4      1      0.169372\n",
      "1          4      1      0.090074\n",
      "2          4      1     -0.160564\n",
      "3          4      1      0.131678\n",
      "4          4      1      0.023742\n",
      "...      ...    ...           ...\n",
      "2043       4      1     -0.011668\n",
      "2044       4      1      0.040745\n",
      "2045       4      1     -1.896426\n",
      "2046       4      1     -0.620909\n",
      "2047       4      1     -1.108641\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "turn off training\n",
      "epoch loss 8.346179842948914\n",
      "      status  party  input_shrunk\n",
      "0          1      1      0.012870\n",
      "1          1      1     -0.034266\n",
      "2          1      1      0.075810\n",
      "3          1      1      0.428671\n",
      "4          1      1      0.167113\n",
      "...      ...    ...           ...\n",
      "2043       1      1      0.735692\n",
      "2044       1      1      1.607339\n",
      "2045       1      1      0.314064\n",
      "2046       1      1     -0.266179\n",
      "2047       1      1     -0.464555\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2827, 0.2634, 0.2451, 0.2088]], grad_fn=<SoftmaxBackward0>)\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.198884\n",
      "1          5      1     -0.333843\n",
      "2          5      1     -0.513041\n",
      "3          5      1      0.245438\n",
      "4          5      1      0.287163\n",
      "...      ...    ...           ...\n",
      "2043       5      1      0.432693\n",
      "2044       5      1     -0.518468\n",
      "2045       5      1     -0.271924\n",
      "2046       5      1     -0.210291\n",
      "2047       5      1     -0.845959\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2831, 0.2635, 0.2450, 0.2084]], grad_fn=<SoftmaxBackward0>)\n",
      "LOSS train 8.346179842948914 valid 1.3537888526916504\n",
      "turn on training\n",
      "running one epoch\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.411736\n",
      "1          5      1      0.019537\n",
      "2          5      1      0.313383\n",
      "3          5      1     -0.088169\n",
      "4          5      1     -0.271366\n",
      "...      ...    ...           ...\n",
      "2043       5      1     -0.026054\n",
      "2044       5      1     -0.318737\n",
      "2045       5      1      0.723295\n",
      "2046       5      1      0.055131\n",
      "2047       5      1     -0.453075\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3541, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.081985\n",
      "1          3      4      0.137535\n",
      "2          3      4     -0.133649\n",
      "3          3      4      0.125648\n",
      "4          3      4      0.155327\n",
      "...      ...    ...           ...\n",
      "2043       3      4     -0.287244\n",
      "2044       3      4      0.133067\n",
      "2045       3      4     -0.510854\n",
      "2046       3      4     -0.383557\n",
      "2047       3      4     -1.129584\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.254739\n",
      "1          3      4     -0.195609\n",
      "2          3      4      0.126331\n",
      "3          3      4      0.262518\n",
      "4          3      4      0.010650\n",
      "...      ...    ...           ...\n",
      "2043       3      4      0.251763\n",
      "2044       3      4      0.957258\n",
      "2045       3      4     -0.232392\n",
      "2046       3      4     -0.157064\n",
      "2047       3      4     -0.443530\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          2      1      0.183673\n",
      "1          2      1      0.244852\n",
      "2          2      1     -0.095650\n",
      "3          2      1     -0.322488\n",
      "4          2      1      0.048414\n",
      "...      ...    ...           ...\n",
      "2043       2      1      0.808546\n",
      "2044       2      1     -0.472243\n",
      "2045       2      1      0.261753\n",
      "2046       2      1     -0.975441\n",
      "2047       2      1     -1.050877\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          4      1      0.169372\n",
      "1          4      1      0.090074\n",
      "2          4      1     -0.160564\n",
      "3          4      1      0.131678\n",
      "4          4      1      0.023742\n",
      "...      ...    ...           ...\n",
      "2043       4      1     -0.011668\n",
      "2044       4      1      0.040745\n",
      "2045       4      1     -1.896426\n",
      "2046       4      1     -0.620909\n",
      "2047       4      1     -1.108641\n",
      "\n",
      "[2048 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          1      4      0.005786\n",
      "1          1      4     -0.121680\n",
      "2          1      4      0.401604\n",
      "3          1      4     -0.332910\n",
      "4          1      4     -0.551901\n",
      "...      ...    ...           ...\n",
      "2043       1      4      0.616539\n",
      "2044       1      4      0.325676\n",
      "2045       1      4     -0.301177\n",
      "2046       1      4     -0.332650\n",
      "2047       1      4     -1.416497\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4280, grad_fn=<DivBackward1>)\n",
      "turn off training\n",
      "epoch loss 8.346179842948914\n",
      "      status  party  input_shrunk\n",
      "0          1      1      0.012870\n",
      "1          1      1     -0.034266\n",
      "2          1      1      0.075810\n",
      "3          1      1      0.428671\n",
      "4          1      1      0.167113\n",
      "...      ...    ...           ...\n",
      "2043       1      1      0.735692\n",
      "2044       1      1      1.607339\n",
      "2045       1      1      0.314064\n",
      "2046       1      1     -0.266179\n",
      "2047       1      1     -0.464555\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2827, 0.2634, 0.2451, 0.2088]], grad_fn=<SoftmaxBackward0>)\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.198884\n",
      "1          5      1     -0.333843\n",
      "2          5      1     -0.513041\n",
      "3          5      1      0.245438\n",
      "4          5      1      0.287163\n",
      "...      ...    ...           ...\n",
      "2043       5      1      0.432693\n",
      "2044       5      1     -0.518468\n",
      "2045       5      1     -0.271924\n",
      "2046       5      1     -0.210291\n",
      "2047       5      1     -0.845959\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2831, 0.2635, 0.2450, 0.2084]], grad_fn=<SoftmaxBackward0>)\n",
      "LOSS train 8.346179842948914 valid 1.3537888526916504\n",
      "turn on training\n",
      "running one epoch\n",
      "      status  party  input_shrunk\n",
      "0          4      1      0.169372\n",
      "1          4      1      0.090074\n",
      "2          4      1     -0.160564\n",
      "3          4      1      0.131678\n",
      "4          4      1      0.023742\n",
      "...      ...    ...           ...\n",
      "2043       4      1     -0.011668\n",
      "2044       4      1      0.040745\n",
      "2045       4      1     -1.896426\n",
      "2046       4      1     -0.620909\n",
      "2047       4      1     -1.108641\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.254739\n",
      "1          3      4     -0.195609\n",
      "2          3      4      0.126331\n",
      "3          3      4      0.262518\n",
      "4          3      4      0.010650\n",
      "...      ...    ...           ...\n",
      "2043       3      4      0.251763\n",
      "2044       3      4      0.957258\n",
      "2045       3      4     -0.232392\n",
      "2046       3      4     -0.157064\n",
      "2047       3      4     -0.443530\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.411736\n",
      "1          5      1      0.019537\n",
      "2          5      1      0.313383\n",
      "3          5      1     -0.088169\n",
      "4          5      1     -0.271366\n",
      "...      ...    ...           ...\n",
      "2043       5      1     -0.026054\n",
      "2044       5      1     -0.318737\n",
      "2045       5      1      0.723295\n",
      "2046       5      1      0.055131\n",
      "2047       5      1     -0.453075\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3541, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.081985\n",
      "1          3      4      0.137535\n",
      "2          3      4     -0.133649\n",
      "3          3      4      0.125648\n",
      "4          3      4      0.155327\n",
      "...      ...    ...           ...\n",
      "2043       3      4     -0.287244\n",
      "2044       3      4      0.133067\n",
      "2045       3      4     -0.510854\n",
      "2046       3      4     -0.383557\n",
      "2047       3      4     -1.129584\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          1      4      0.005786\n",
      "1          1      4     -0.121680\n",
      "2          1      4      0.401604\n",
      "3          1      4     -0.332910\n",
      "4          1      4     -0.551901\n",
      "...      ...    ...           ...\n",
      "2043       1      4      0.616539\n",
      "2044       1      4      0.325676\n",
      "2045       1      4     -0.301177\n",
      "2046       1      4     -0.332650\n",
      "2047       1      4     -1.416497\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4280, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          2      1      0.183673\n",
      "1          2      1      0.244852\n",
      "2          2      1     -0.095650\n",
      "3          2      1     -0.322488\n",
      "4          2      1      0.048414\n",
      "...      ...    ...           ...\n",
      "2043       2      1      0.808546\n",
      "2044       2      1     -0.472243\n",
      "2045       2      1      0.261753\n",
      "2046       2      1     -0.975441\n",
      "2047       2      1     -1.050877\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "turn off training\n",
      "epoch loss 8.346179842948914\n",
      "      status  party  input_shrunk\n",
      "0          1      1      0.012870\n",
      "1          1      1     -0.034266\n",
      "2          1      1      0.075810\n",
      "3          1      1      0.428671\n",
      "4          1      1      0.167113\n",
      "...      ...    ...           ...\n",
      "2043       1      1      0.735692\n",
      "2044       1      1      1.607339\n",
      "2045       1      1      0.314064\n",
      "2046       1      1     -0.266179\n",
      "2047       1      1     -0.464555\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2827, 0.2634, 0.2451, 0.2088]], grad_fn=<SoftmaxBackward0>)\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.198884\n",
      "1          5      1     -0.333843\n",
      "2          5      1     -0.513041\n",
      "3          5      1      0.245438\n",
      "4          5      1      0.287163\n",
      "...      ...    ...           ...\n",
      "2043       5      1      0.432693\n",
      "2044       5      1     -0.518468\n",
      "2045       5      1     -0.271924\n",
      "2046       5      1     -0.210291\n",
      "2047       5      1     -0.845959\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2831, 0.2635, 0.2450, 0.2084]], grad_fn=<SoftmaxBackward0>)\n",
      "LOSS train 8.346179842948914 valid 1.3537888526916504\n",
      "turn on training\n",
      "running one epoch\n",
      "      status  party  input_shrunk\n",
      "0          2      1      0.183673\n",
      "1          2      1      0.244852\n",
      "2          2      1     -0.095650\n",
      "3          2      1     -0.322488\n",
      "4          2      1      0.048414\n",
      "...      ...    ...           ...\n",
      "2043       2      1      0.808546\n",
      "2044       2      1     -0.472243\n",
      "2045       2      1      0.261753\n",
      "2046       2      1     -0.975441\n",
      "2047       2      1     -1.050877\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          4      1      0.169372\n",
      "1          4      1      0.090074\n",
      "2          4      1     -0.160564\n",
      "3          4      1      0.131678\n",
      "4          4      1      0.023742\n",
      "...      ...    ...           ...\n",
      "2043       4      1     -0.011668\n",
      "2044       4      1      0.040745\n",
      "2045       4      1     -1.896426\n",
      "2046       4      1     -0.620909\n",
      "2047       4      1     -1.108641\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.254739\n",
      "1          3      4     -0.195609\n",
      "2          3      4      0.126331\n",
      "3          3      4      0.262518\n",
      "4          3      4      0.010650\n",
      "...      ...    ...           ...\n",
      "2043       3      4      0.251763\n",
      "2044       3      4      0.957258\n",
      "2045       3      4     -0.232392\n",
      "2046       3      4     -0.157064\n",
      "2047       3      4     -0.443530\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.411736\n",
      "1          5      1      0.019537\n",
      "2          5      1      0.313383\n",
      "3          5      1     -0.088169\n",
      "4          5      1     -0.271366\n",
      "...      ...    ...           ...\n",
      "2043       5      1     -0.026054\n",
      "2044       5      1     -0.318737\n",
      "2045       5      1      0.723295\n",
      "2046       5      1      0.055131\n",
      "2047       5      1     -0.453075\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3541, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.081985\n",
      "1          3      4      0.137535\n",
      "2          3      4     -0.133649\n",
      "3          3      4      0.125648\n",
      "4          3      4      0.155327\n",
      "...      ...    ...           ...\n",
      "2043       3      4     -0.287244\n",
      "2044       3      4      0.133067\n",
      "2045       3      4     -0.510854\n",
      "2046       3      4     -0.383557\n",
      "2047       3      4     -1.129584\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          1      4      0.005786\n",
      "1          1      4     -0.121680\n",
      "2          1      4      0.401604\n",
      "3          1      4     -0.332910\n",
      "4          1      4     -0.551901\n",
      "...      ...    ...           ...\n",
      "2043       1      4      0.616539\n",
      "2044       1      4      0.325676\n",
      "2045       1      4     -0.301177\n",
      "2046       1      4     -0.332650\n",
      "2047       1      4     -1.416497\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4280, grad_fn=<DivBackward1>)\n",
      "turn off training\n",
      "epoch loss 8.346179842948914\n",
      "      status  party  input_shrunk\n",
      "0          1      1      0.012870\n",
      "1          1      1     -0.034266\n",
      "2          1      1      0.075810\n",
      "3          1      1      0.428671\n",
      "4          1      1      0.167113\n",
      "...      ...    ...           ...\n",
      "2043       1      1      0.735692\n",
      "2044       1      1      1.607339\n",
      "2045       1      1      0.314064\n",
      "2046       1      1     -0.266179\n",
      "2047       1      1     -0.464555\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2827, 0.2634, 0.2451, 0.2088]], grad_fn=<SoftmaxBackward0>)\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.198884\n",
      "1          5      1     -0.333843\n",
      "2          5      1     -0.513041\n",
      "3          5      1      0.245438\n",
      "4          5      1      0.287163\n",
      "...      ...    ...           ...\n",
      "2043       5      1      0.432693\n",
      "2044       5      1     -0.518468\n",
      "2045       5      1     -0.271924\n",
      "2046       5      1     -0.210291\n",
      "2047       5      1     -0.845959\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2831, 0.2635, 0.2450, 0.2084]], grad_fn=<SoftmaxBackward0>)\n",
      "LOSS train 8.346179842948914 valid 1.3537888526916504\n",
      "turn on training\n",
      "running one epoch\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.081985\n",
      "1          3      4      0.137535\n",
      "2          3      4     -0.133649\n",
      "3          3      4      0.125648\n",
      "4          3      4      0.155327\n",
      "...      ...    ...           ...\n",
      "2043       3      4     -0.287244\n",
      "2044       3      4      0.133067\n",
      "2045       3      4     -0.510854\n",
      "2046       3      4     -0.383557\n",
      "2047       3      4     -1.129584\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      status  party  input_shrunk\n",
      "0          1      4      0.005786\n",
      "1          1      4     -0.121680\n",
      "2          1      4      0.401604\n",
      "3          1      4     -0.332910\n",
      "4          1      4     -0.551901\n",
      "...      ...    ...           ...\n",
      "2043       1      4      0.616539\n",
      "2044       1      4      0.325676\n",
      "2045       1      4     -0.301177\n",
      "2046       1      4     -0.332650\n",
      "2047       1      4     -1.416497\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4280, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          4      1      0.169372\n",
      "1          4      1      0.090074\n",
      "2          4      1     -0.160564\n",
      "3          4      1      0.131678\n",
      "4          4      1      0.023742\n",
      "...      ...    ...           ...\n",
      "2043       4      1     -0.011668\n",
      "2044       4      1      0.040745\n",
      "2045       4      1     -1.896426\n",
      "2046       4      1     -0.620909\n",
      "2047       4      1     -1.108641\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          2      1      0.183673\n",
      "1          2      1      0.244852\n",
      "2          2      1     -0.095650\n",
      "3          2      1     -0.322488\n",
      "4          2      1      0.048414\n",
      "...      ...    ...           ...\n",
      "2043       2      1      0.808546\n",
      "2044       2      1     -0.472243\n",
      "2045       2      1      0.261753\n",
      "2046       2      1     -0.975441\n",
      "2047       2      1     -1.050877\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.254739\n",
      "1          3      4     -0.195609\n",
      "2          3      4      0.126331\n",
      "3          3      4      0.262518\n",
      "4          3      4      0.010650\n",
      "...      ...    ...           ...\n",
      "2043       3      4      0.251763\n",
      "2044       3      4      0.957258\n",
      "2045       3      4     -0.232392\n",
      "2046       3      4     -0.157064\n",
      "2047       3      4     -0.443530\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.411736\n",
      "1          5      1      0.019537\n",
      "2          5      1      0.313383\n",
      "3          5      1     -0.088169\n",
      "4          5      1     -0.271366\n",
      "...      ...    ...           ...\n",
      "2043       5      1     -0.026054\n",
      "2044       5      1     -0.318737\n",
      "2045       5      1      0.723295\n",
      "2046       5      1      0.055131\n",
      "2047       5      1     -0.453075\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3541, grad_fn=<DivBackward1>)\n",
      "turn off training\n",
      "epoch loss 8.346179842948914\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.198884\n",
      "1          5      1     -0.333843\n",
      "2          5      1     -0.513041\n",
      "3          5      1      0.245438\n",
      "4          5      1      0.287163\n",
      "...      ...    ...           ...\n",
      "2043       5      1      0.432693\n",
      "2044       5      1     -0.518468\n",
      "2045       5      1     -0.271924\n",
      "2046       5      1     -0.210291\n",
      "2047       5      1     -0.845959\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2831, 0.2635, 0.2450, 0.2084]], grad_fn=<SoftmaxBackward0>)\n",
      "      status  party  input_shrunk\n",
      "0          1      1      0.012870\n",
      "1          1      1     -0.034266\n",
      "2          1      1      0.075810\n",
      "3          1      1      0.428671\n",
      "4          1      1      0.167113\n",
      "...      ...    ...           ...\n",
      "2043       1      1      0.735692\n",
      "2044       1      1      1.607339\n",
      "2045       1      1      0.314064\n",
      "2046       1      1     -0.266179\n",
      "2047       1      1     -0.464555\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2827, 0.2634, 0.2451, 0.2088]], grad_fn=<SoftmaxBackward0>)\n",
      "LOSS train 8.346179842948914 valid 1.3537888526916504\n",
      "turn on training\n",
      "running one epoch\n",
      "      status  party  input_shrunk\n",
      "0          2      1      0.183673\n",
      "1          2      1      0.244852\n",
      "2          2      1     -0.095650\n",
      "3          2      1     -0.322488\n",
      "4          2      1      0.048414\n",
      "...      ...    ...           ...\n",
      "2043       2      1      0.808546\n",
      "2044       2      1     -0.472243\n",
      "2045       2      1      0.261753\n",
      "2046       2      1     -0.975441\n",
      "2047       2      1     -1.050877\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.081985\n",
      "1          3      4      0.137535\n",
      "2          3      4     -0.133649\n",
      "3          3      4      0.125648\n",
      "4          3      4      0.155327\n",
      "...      ...    ...           ...\n",
      "2043       3      4     -0.287244\n",
      "2044       3      4      0.133067\n",
      "2045       3      4     -0.510854\n",
      "2046       3      4     -0.383557\n",
      "2047       3      4     -1.129584\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          1      4      0.005786\n",
      "1          1      4     -0.121680\n",
      "2          1      4      0.401604\n",
      "3          1      4     -0.332910\n",
      "4          1      4     -0.551901\n",
      "...      ...    ...           ...\n",
      "2043       1      4      0.616539\n",
      "2044       1      4      0.325676\n",
      "2045       1      4     -0.301177\n",
      "2046       1      4     -0.332650\n",
      "2047       1      4     -1.416497\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4280, grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      status  party  input_shrunk\n",
      "0          5      1      0.411736\n",
      "1          5      1      0.019537\n",
      "2          5      1      0.313383\n",
      "3          5      1     -0.088169\n",
      "4          5      1     -0.271366\n",
      "...      ...    ...           ...\n",
      "2043       5      1     -0.026054\n",
      "2044       5      1     -0.318737\n",
      "2045       5      1      0.723295\n",
      "2046       5      1      0.055131\n",
      "2047       5      1     -0.453075\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3541, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          4      1      0.169372\n",
      "1          4      1      0.090074\n",
      "2          4      1     -0.160564\n",
      "3          4      1      0.131678\n",
      "4          4      1      0.023742\n",
      "...      ...    ...           ...\n",
      "2043       4      1     -0.011668\n",
      "2044       4      1      0.040745\n",
      "2045       4      1     -1.896426\n",
      "2046       4      1     -0.620909\n",
      "2047       4      1     -1.108641\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.254739\n",
      "1          3      4     -0.195609\n",
      "2          3      4      0.126331\n",
      "3          3      4      0.262518\n",
      "4          3      4      0.010650\n",
      "...      ...    ...           ...\n",
      "2043       3      4      0.251763\n",
      "2044       3      4      0.957258\n",
      "2045       3      4     -0.232392\n",
      "2046       3      4     -0.157064\n",
      "2047       3      4     -0.443530\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "turn off training\n",
      "epoch loss 8.346179842948914\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.198884\n",
      "1          5      1     -0.333843\n",
      "2          5      1     -0.513041\n",
      "3          5      1      0.245438\n",
      "4          5      1      0.287163\n",
      "...      ...    ...           ...\n",
      "2043       5      1      0.432693\n",
      "2044       5      1     -0.518468\n",
      "2045       5      1     -0.271924\n",
      "2046       5      1     -0.210291\n",
      "2047       5      1     -0.845959\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2831, 0.2635, 0.2450, 0.2084]], grad_fn=<SoftmaxBackward0>)\n",
      "      status  party  input_shrunk\n",
      "0          1      1      0.012870\n",
      "1          1      1     -0.034266\n",
      "2          1      1      0.075810\n",
      "3          1      1      0.428671\n",
      "4          1      1      0.167113\n",
      "...      ...    ...           ...\n",
      "2043       1      1      0.735692\n",
      "2044       1      1      1.607339\n",
      "2045       1      1      0.314064\n",
      "2046       1      1     -0.266179\n",
      "2047       1      1     -0.464555\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2827, 0.2634, 0.2451, 0.2088]], grad_fn=<SoftmaxBackward0>)\n",
      "LOSS train 8.346179842948914 valid 1.3537888526916504\n",
      "turn on training\n",
      "running one epoch\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.411736\n",
      "1          5      1      0.019537\n",
      "2          5      1      0.313383\n",
      "3          5      1     -0.088169\n",
      "4          5      1     -0.271366\n",
      "...      ...    ...           ...\n",
      "2043       5      1     -0.026054\n",
      "2044       5      1     -0.318737\n",
      "2045       5      1      0.723295\n",
      "2046       5      1      0.055131\n",
      "2047       5      1     -0.453075\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3541, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.254739\n",
      "1          3      4     -0.195609\n",
      "2          3      4      0.126331\n",
      "3          3      4      0.262518\n",
      "4          3      4      0.010650\n",
      "...      ...    ...           ...\n",
      "2043       3      4      0.251763\n",
      "2044       3      4      0.957258\n",
      "2045       3      4     -0.232392\n",
      "2046       3      4     -0.157064\n",
      "2047       3      4     -0.443530\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          4      1      0.169372\n",
      "1          4      1      0.090074\n",
      "2          4      1     -0.160564\n",
      "3          4      1      0.131678\n",
      "4          4      1      0.023742\n",
      "...      ...    ...           ...\n",
      "2043       4      1     -0.011668\n",
      "2044       4      1      0.040745\n",
      "2045       4      1     -1.896426\n",
      "2046       4      1     -0.620909\n",
      "2047       4      1     -1.108641\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          1      4      0.005786\n",
      "1          1      4     -0.121680\n",
      "2          1      4      0.401604\n",
      "3          1      4     -0.332910\n",
      "4          1      4     -0.551901\n",
      "...      ...    ...           ...\n",
      "2043       1      4      0.616539\n",
      "2044       1      4      0.325676\n",
      "2045       1      4     -0.301177\n",
      "2046       1      4     -0.332650\n",
      "2047       1      4     -1.416497\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4280, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          2      1      0.183673\n",
      "1          2      1      0.244852\n",
      "2          2      1     -0.095650\n",
      "3          2      1     -0.322488\n",
      "4          2      1      0.048414\n",
      "...      ...    ...           ...\n",
      "2043       2      1      0.808546\n",
      "2044       2      1     -0.472243\n",
      "2045       2      1      0.261753\n",
      "2046       2      1     -0.975441\n",
      "2047       2      1     -1.050877\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      status  party  input_shrunk\n",
      "0          3      4      0.081985\n",
      "1          3      4      0.137535\n",
      "2          3      4     -0.133649\n",
      "3          3      4      0.125648\n",
      "4          3      4      0.155327\n",
      "...      ...    ...           ...\n",
      "2043       3      4     -0.287244\n",
      "2044       3      4      0.133067\n",
      "2045       3      4     -0.510854\n",
      "2046       3      4     -0.383557\n",
      "2047       3      4     -1.129584\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "turn off training\n",
      "epoch loss 8.346179842948914\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.198884\n",
      "1          5      1     -0.333843\n",
      "2          5      1     -0.513041\n",
      "3          5      1      0.245438\n",
      "4          5      1      0.287163\n",
      "...      ...    ...           ...\n",
      "2043       5      1      0.432693\n",
      "2044       5      1     -0.518468\n",
      "2045       5      1     -0.271924\n",
      "2046       5      1     -0.210291\n",
      "2047       5      1     -0.845959\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2831, 0.2635, 0.2450, 0.2084]], grad_fn=<SoftmaxBackward0>)\n",
      "      status  party  input_shrunk\n",
      "0          1      1      0.012870\n",
      "1          1      1     -0.034266\n",
      "2          1      1      0.075810\n",
      "3          1      1      0.428671\n",
      "4          1      1      0.167113\n",
      "...      ...    ...           ...\n",
      "2043       1      1      0.735692\n",
      "2044       1      1      1.607339\n",
      "2045       1      1      0.314064\n",
      "2046       1      1     -0.266179\n",
      "2047       1      1     -0.464555\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2827, 0.2634, 0.2451, 0.2088]], grad_fn=<SoftmaxBackward0>)\n",
      "LOSS train 8.346179842948914 valid 1.3537888526916504\n",
      "turn on training\n",
      "running one epoch\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.411736\n",
      "1          5      1      0.019537\n",
      "2          5      1      0.313383\n",
      "3          5      1     -0.088169\n",
      "4          5      1     -0.271366\n",
      "...      ...    ...           ...\n",
      "2043       5      1     -0.026054\n",
      "2044       5      1     -0.318737\n",
      "2045       5      1      0.723295\n",
      "2046       5      1      0.055131\n",
      "2047       5      1     -0.453075\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3541, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          2      1      0.183673\n",
      "1          2      1      0.244852\n",
      "2          2      1     -0.095650\n",
      "3          2      1     -0.322488\n",
      "4          2      1      0.048414\n",
      "...      ...    ...           ...\n",
      "2043       2      1      0.808546\n",
      "2044       2      1     -0.472243\n",
      "2045       2      1      0.261753\n",
      "2046       2      1     -0.975441\n",
      "2047       2      1     -1.050877\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          4      1      0.169372\n",
      "1          4      1      0.090074\n",
      "2          4      1     -0.160564\n",
      "3          4      1      0.131678\n",
      "4          4      1      0.023742\n",
      "...      ...    ...           ...\n",
      "2043       4      1     -0.011668\n",
      "2044       4      1      0.040745\n",
      "2045       4      1     -1.896426\n",
      "2046       4      1     -0.620909\n",
      "2047       4      1     -1.108641\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.3538, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.081985\n",
      "1          3      4      0.137535\n",
      "2          3      4     -0.133649\n",
      "3          3      4      0.125648\n",
      "4          3      4      0.155327\n",
      "...      ...    ...           ...\n",
      "2043       3      4     -0.287244\n",
      "2044       3      4      0.133067\n",
      "2045       3      4     -0.510854\n",
      "2046       3      4     -0.383557\n",
      "2047       3      4     -1.129584\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          3      4      0.254739\n",
      "1          3      4     -0.195609\n",
      "2          3      4      0.126331\n",
      "3          3      4      0.262518\n",
      "4          3      4      0.010650\n",
      "...      ...    ...           ...\n",
      "2043       3      4      0.251763\n",
      "2044       3      4      0.957258\n",
      "2045       3      4     -0.232392\n",
      "2046       3      4     -0.157064\n",
      "2047       3      4     -0.443530\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4283, grad_fn=<DivBackward1>)\n",
      "      status  party  input_shrunk\n",
      "0          1      4      0.005786\n",
      "1          1      4     -0.121680\n",
      "2          1      4      0.401604\n",
      "3          1      4     -0.332910\n",
      "4          1      4     -0.551901\n",
      "...      ...    ...           ...\n",
      "2043       1      4      0.616539\n",
      "2044       1      4      0.325676\n",
      "2045       1      4     -0.301177\n",
      "2046       1      4     -0.332650\n",
      "2047       1      4     -1.416497\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "tensor(1.4280, grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn off training\n",
      "epoch loss 8.346179842948914\n",
      "      status  party  input_shrunk\n",
      "0          5      1      0.198884\n",
      "1          5      1     -0.333843\n",
      "2          5      1     -0.513041\n",
      "3          5      1      0.245438\n",
      "4          5      1      0.287163\n",
      "...      ...    ...           ...\n",
      "2043       5      1      0.432693\n",
      "2044       5      1     -0.518468\n",
      "2045       5      1     -0.271924\n",
      "2046       5      1     -0.210291\n",
      "2047       5      1     -0.845959\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2831, 0.2635, 0.2450, 0.2084]], grad_fn=<SoftmaxBackward0>)\n",
      "      status  party  input_shrunk\n",
      "0          1      1      0.012870\n",
      "1          1      1     -0.034266\n",
      "2          1      1      0.075810\n",
      "3          1      1      0.428671\n",
      "4          1      1      0.167113\n",
      "...      ...    ...           ...\n",
      "2043       1      1      0.735692\n",
      "2044       1      1      1.607339\n",
      "2045       1      1      0.314064\n",
      "2046       1      1     -0.266179\n",
      "2047       1      1     -0.464555\n",
      "\n",
      "[2048 rows x 3 columns]\n",
      "label : tensor([[1., 0., 0., 0.]])\n",
      "vOutput: tensor([[0.2827, 0.2634, 0.2451, 0.2088]], grad_fn=<SoftmaxBackward0>)\n",
      "LOSS train 8.346179842948914 valid 1.3537888526916504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\1004825444.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  party_arr = np.zeros(4,dtype=np.int)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_25856\\685939361.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.output(x)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "start_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(start_time))\n",
    "EPOCHS = 10\n",
    "epoch_num = 0\n",
    "title_model = TitlePartyModel()\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"turn on training\")\n",
    "    title_model.train(True)\n",
    "    print(\"running one epoch\")\n",
    "    last_epoch_loss = train_one_epoch(epoch_num,title_model, writer)\n",
    "    print(\"turn off training\")\n",
    "    print(f'epoch loss {last_epoch_loss}')\n",
    "\n",
    "    title_model.train(False)\n",
    "\n",
    "    running_validation_loss = 0.0\n",
    "    for i, vdata in enumerate(test_loader):\n",
    "        vinputs, vlabel = vdata\n",
    "        print(f\"label : {vlabel}\")\n",
    "        voutputs = title_model(vinputs)\n",
    "        print(f\"vOutput: {voutputs}\")\n",
    "        vloss = loss_fn(voutputs, vlabel)\n",
    "        running_validation_loss += vloss\n",
    "\n",
    "    avg_vloss = running_validation_loss / len(test_loader)\n",
    "    losses.append(avg_vloss)\n",
    "    print('LOSS train {} valid {}'.format(last_epoch_loss, avg_vloss))\n",
    "#    writer.add_scalars(\"Training vs Valiation loss\",{\"training\": last_epoch_loss, \"validation\": avg_vloss}, epoch_num+1)\n",
    "#    writer.flush()\n",
    "    epoch_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.4816, grad_fn=<DivBackward0>), tensor(1.4816, grad_fn=<DivBackward0>), tensor(1.4816, grad_fn=<DivBackward0>), tensor(1.4816, grad_fn=<DivBackward0>), tensor(1.4816, grad_fn=<DivBackward0>), tensor(1.4816, grad_fn=<DivBackward0>), tensor(1.4816, grad_fn=<DivBackward0>), tensor(1.4816, grad_fn=<DivBackward0>), tensor(1.4816, grad_fn=<DivBackward0>), tensor(1.4816, grad_fn=<DivBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "print(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}